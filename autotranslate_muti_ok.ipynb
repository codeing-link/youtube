{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeing-link/youtube/blob/main/autotranslate_muti_ok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96kvih9mXkNN"
      },
      "source": [
        "# **Videos Transcription and Translation with Faster Whisper and ChatGPT**\n",
        "\n",
        "\n",
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/lewangdev/autotranslate/blob/main/autotranslate.ipynb)](https://colab.research.google.com/github/lewangdev/autotranslate/blob/main/autotranslate.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/lewangdev/autotranslate)](https://github.com/lewangdev/autotranslate)\n",
        "\n",
        "This Notebook will guide you through the transcription and translation of video using [Faster Whisper](https://github.com/guillaumekln/faster-whisper) and ChatGPT. You'll be able to explore most inference parameters or use the Notebook as-is to store the transcript, translation and video audio in your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QshUbLqpX7L4"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Check GPU type** ğŸ•µï¸\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Install libraries** ğŸ—ï¸\n",
        "#@markdown This cell will take a little while to download several libraries.\n",
        "\n",
        "#@markdown ---\n",
        "! pip install faster-whisper==0.10.0\n",
        "! pip install yt-dlp==2023.11.16\n",
        "! pip install openai==0.28.1\n",
        "\n",
        "! wget https://github.com/Purfview/whisper-standalone-win/releases/download/libs/cuBLAS.and.cuDNN_linux.zip\n",
        "! unzip -o cuBLAS.and.cuDNN_linux.zip -d /usr/lib\n"
      ],
      "metadata": {
        "id": "DDX38HH5xLot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfG0E_WbRFI0"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Import libraries for Python** ğŸ\n",
        "\n",
        "#@markdown This cell will import all libraries for python code.\n",
        "import sys\n",
        "import warnings\n",
        "from faster_whisper import WhisperModel\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zwGAsr4sIgd"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Optional:** Save data in Google Drive ğŸ’¾\n",
        "#@markdown Enter a Google Drive path and run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "#@markdown ---\n",
        "drive_path = \"Colab Notebooks/Videos Transcription and Translation\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMhrSq_GZ6kA"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Model selection** ğŸ§ \n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~0.8 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1.0 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~1.4 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~2.7 GB     |      ~2x       |\n",
        "#@markdown | large-v1  |   1550 M   |        N/A         |      `large-v1`       |    ~4.3 GB     |       1x       |\n",
        "#@markdown | large-v2  |   1550 M   |        N/A         |      `large-v2`       |    ~4.3 GB     |       1x       |\n",
        "#@markdown | large-v3  |   1550 M   |        N/A         |      `large-v2`       |    ~3.6 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "model_size = 'large-v2' #@param ['tiny', 'tiny.en', 'base', 'base.en', 'small', 'small.en', 'medium', 'medium.en', 'large-v1', 'large-v2', 'large-v3']\n",
        "device_type = \"cuda\" #@param {type:\"string\"} ['cuda', 'cpu']\n",
        "compute_type = \"float16\" #@param {type:\"string\"} ['float16', 'int8_float16', 'int8']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "model = WhisperModel(model_size, device=device_type, compute_type=compute_type)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xYLPZQX9S7tU"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Video selection** ğŸ“º\n",
        "\n",
        "#@markdown Enter the URL of the video you want to transcribe, wether you want to save the audio file in your Google Drive, and run the cell.\n",
        "\n",
        "Type = \"Video or playlist URL\" #@param ['Video or playlist URL', 'Google Drive']\n",
        "#@markdown ---\n",
        "#@markdown #### **Video or playlist URL**\n",
        "URL = \"https://www.youtube.com/playlist?list=PL-c0DN3fTeQcbHY41LZ_5NZaCf1_3YLQa\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"Colab Notebooks/transcription/my_video.mp4\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Video or playlist URL\":\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # â„¹ï¸ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **å°†å½“å‰ç›®å½•çš„wavæ–‡ä»¶ä¿å­˜åˆ°åˆ—è¡¨ä¸­**\n",
        "import os\n",
        "\n",
        "# è·å–å½“å‰ç›®å½•ä¸‹æ‰€æœ‰çš„ .wav æ–‡ä»¶\n",
        "video_path_local_list = [file for file in os.listdir('.') if file.endswith('.wav')]\n",
        "\n",
        "# æ‰“å°åˆ—è¡¨å†…å®¹ï¼Œæ£€æŸ¥.wavæ–‡ä»¶\n",
        "print(video_path_local_list)"
      ],
      "metadata": {
        "id": "lUm-FzM5CUwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ad6n1m4deAHp",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "#@markdown # **Run the model** ğŸš€\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "\n",
        "def format_time(time_str):\n",
        "    # è§£ææ—¶é—´å­—ç¬¦ä¸²\n",
        "    hours, minutes, seconds_micro = time_str.split(':')\n",
        "    seconds, microseconds = seconds_micro.split(',')\n",
        "    # æ ¼å¼åŒ–æ—¶é—´ä¸º HH:MM:SS,mmm (æ¯«ç§’ä¸ºä¸‰ä½æ•°)\n",
        "    formatted_time = f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{int(microseconds[:3]):03d}\"\n",
        "    return formatted_time\n",
        "\n",
        "def time_format_to_seconds(t):\n",
        "    h, m, s_ms = t.split(':')\n",
        "    s, ms = s_ms.split(',')\n",
        "    return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000\n",
        "\n",
        "\n",
        "def write_to_srt_file(segments, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
        "        for index, segment in enumerate(segments, start=1):\n",
        "            start_seconds = time_format_to_seconds(segment['start'])\n",
        "            end_seconds = time_format_to_seconds(segment['end'])\n",
        "            file.write(f\"{index}\\n\")\n",
        "            file.write(f\"{seconds_to_time_format(start_seconds)} --> {seconds_to_time_format(end_seconds)}\\n\")\n",
        "            file.write(f\"{segment['text']}\\n\\n\")\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "def seconds_to_time_format(s):\n",
        "    # Convert seconds to hours, minutes, seconds, and milliseconds\n",
        "    hours = s // 3600\n",
        "    s %= 3600\n",
        "    minutes = s // 60\n",
        "    s %= 60\n",
        "    seconds = s // 1\n",
        "    milliseconds = round((s % 1) * 1000)\n",
        "\n",
        "    # Return the formatted string\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{int(milliseconds):03d}\"\n",
        "\n",
        "\n",
        "#@markdown ## **Parameters** âš™ï¸\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown #### Language\n",
        "language_options = {\n",
        "    \"Auto Detect\": \"auto\",\n",
        "    \"English\": \"en\",\n",
        "    \"ä¸­æ–‡(Chinese)\": \"zh\",\n",
        "    \"æ—¥æœ¬èª(Japanese)\": \"ja\",\n",
        "    \"Deutsch(German)\": \"de\",\n",
        "    \"FranÃ§ais(French)\": \"fr\"\n",
        "}\n",
        "\n",
        "language_option = \"Auto Detect\" #@param [\"Auto Detect\", \"English\", \"ä¸­æ–‡(Chinese)\", \"æ—¥æœ¬èª(Japanese)\", \"Deutsch(German)\", \"FranÃ§ais(French)\"] {allow-input: true}\n",
        "language = language_options.get(language_option, language_option)\n",
        "\n",
        "#@markdown #### initial prompt\n",
        "initial_prompt = \"Hello, Let's begin to talk.\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### Word-level timestamps\n",
        "word_level_timestamps = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### VAD filter\n",
        "vad_filter = False #@param {type:\"boolean\"}\n",
        "vad_filter_min_silence_duration_ms = 50 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "  segments, info = model.transcribe(str(video_path_local), beam_size=5,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    initial_prompt=initial_prompt,\n",
        "                                    word_timestamps=word_level_timestamps,\n",
        "                                    vad_filter=vad_filter,\n",
        "                                    vad_parameters=dict(min_silence_duration_ms=vad_filter_min_silence_duration_ms))\n",
        "\n",
        "  language_detected = info.language\n",
        "  display(Markdown(f\"Detected language '{info.language}' with probability {info.language_probability}\"))\n",
        "\n",
        "  fragments = []\n",
        "  line_text = []\n",
        "\n",
        "  for segment in segments:\n",
        "    print(f\"[{seconds_to_time_format(segment.start)} --> {seconds_to_time_format(segment.end)}] {segment.text}\")\n",
        "\n",
        "    start_time = format_time(seconds_to_time_format(segment.start))\n",
        "    end_time = format_time(seconds_to_time_format(segment.end))\n",
        "    text = segment.text\n",
        "    line_text.append({'start': start_time, 'end': end_time, 'text': text})\n",
        "\n",
        "    if word_level_timestamps:\n",
        "      for word in segment.words:\n",
        "        ts_start = seconds_to_time_format(word.start)\n",
        "        ts_end = seconds_to_time_format(word.end)\n",
        "        #print(f\"[{ts_start} --> {ts_end}] {word.word}\")\n",
        "        fragments.append(dict(start=word.start,end=word.end,text=word.word))\n",
        "    else:\n",
        "      ts_start = seconds_to_time_format(segment.start)\n",
        "      ts_end = seconds_to_time_format(segment.end)\n",
        "      #print(f\"[{ts_start} --> {ts_end}] {segment.text}\")\n",
        "      fragments.append(dict(start=segment.start,end=segment.end,text=segment.text))\n",
        "\n",
        "\n",
        "\n",
        "  write_to_srt_file(line_text, video_path_local.replace(\".wav\", \".srt\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **ä¿å­˜srtæ–‡ä»¶ï¼Œåˆ é™¤æœ¬åœ°çš„srtå’Œwavæ–‡ä»¶**\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_srt_files_to_target(target_directory):\n",
        "    # è·å–å½“å‰ç›®å½•\n",
        "    current_directory = os.getcwd()\n",
        "\n",
        "    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨\n",
        "    if not os.path.exists(target_directory):\n",
        "        os.makedirs(target_directory)\n",
        "\n",
        "    # éå†å½“å‰ç›®å½•ä¸­çš„æ–‡ä»¶\n",
        "    for filename in os.listdir(current_directory):\n",
        "        if filename.endswith(\".srt\"):\n",
        "            # æ„å»ºå®Œæ•´çš„æºæ–‡ä»¶è·¯å¾„å’Œç›®æ ‡æ–‡ä»¶è·¯å¾„\n",
        "            source_path = os.path.join(current_directory, filename)\n",
        "            target_path = os.path.join(target_directory, filename)\n",
        "\n",
        "            # å¤åˆ¶æ–‡ä»¶\n",
        "            shutil.copy(source_path, target_path)\n",
        "            print(f\"Copied: {filename}\")\n",
        "\n",
        "# æŒ‡å®šç›®æ ‡ç›®å½•ï¼ˆè¿™é‡Œç›´æ¥æŒ‡å®šä¸º './drive/Mydrive/srt'ï¼‰\n",
        "#print(drive_whisper_path)\n",
        "target_folder = drive_whisper_path\n",
        "copy_srt_files_to_target(target_folder)\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "def delete_files_with_extensions(extensions):\n",
        "    # è·å–å½“å‰ç›®å½•\n",
        "    current_directory = os.getcwd()\n",
        "\n",
        "    # éå†å½“å‰ç›®å½•ä¸­çš„æ–‡ä»¶\n",
        "    for filename in os.listdir(current_directory):\n",
        "        if any(filename.endswith(ext) for ext in extensions):\n",
        "            # æ„å»ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„\n",
        "            file_path = os.path.join(current_directory, filename)\n",
        "\n",
        "            # åˆ é™¤æ–‡ä»¶\n",
        "            os.remove(file_path)\n",
        "            print(f\"Deleted: {filename}\")\n",
        "\n",
        "# è¦åˆ é™¤çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨\n",
        "extensions_to_delete = [\".srt\", \".wav\"]\n",
        "delete_files_with_extensions(extensions_to_delete)"
      ],
      "metadata": {
        "id": "Pf3Fh-2LMc4Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}